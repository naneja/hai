{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8f7ef3e-0652-453a-ab30-76796c1fcf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as tm\n",
    "import numpy as np\n",
    "import threading\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "import sounddevice as sd\n",
    "import librosa\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cfa1b06-d7de-45d9-9ca1-53eeb42fc9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0a9d713-631e-40ff-a719-ca6e7bf209aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "BC_RATE = 1.3*c #1.3\n",
    "\n",
    "# Audio settings\n",
    "SAMPLERATE = 44100\n",
    "CHANNELS = 1\n",
    "DURATION = 0.5  # Duration of each audio capture in seconds\n",
    "\n",
    "speech_duration, silence_duration = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe7bde3c-4439-4c88-bd47-928c92000dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " BC \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def play_soft_beep():\n",
    "    # Parameters for the beep\n",
    "    frequency = 440  # Frequency of the beep (in Hz)\n",
    "    duration = 0.2   # Duration of the beep (in seconds)\n",
    "    amplitude = 0.1  # Amplitude of the beep (0.0 to 1.0 for soft to loud)\n",
    "\n",
    "    # Generate the time points\n",
    "    sample_rate = 44100  # Samples per second\n",
    "    t = np.linspace(0, duration, int(sample_rate * duration), endpoint=False)\n",
    "\n",
    "    # Generate the beep as a sine wave\n",
    "    beep = amplitude * np.sin(2 * np.pi * frequency * t)\n",
    "\n",
    "    print(\" BC \", end=\"\\n\\n\")\n",
    "    # Play the beep\n",
    "    sd.play(beep, sample_rate)\n",
    "    sd.wait()  # Wait until the sound is done playing\n",
    "play_soft_beep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8da3d53f-7981-4dd4-a3a3-d973214e5818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorrelate(signal):\n",
    "    \"\"\"\n",
    "    Autocorrelates the provided signal.\n",
    "\n",
    "    Args:\n",
    "    signal (numpy array): The audio signal.\n",
    "\n",
    "    Returns:\n",
    "    numpy array: Autocorrelation of the signal.\n",
    "    \"\"\"\n",
    "    if signal.size == 0:\n",
    "        # Handle the empty signal appropriately\n",
    "        return np.array([])\n",
    "\n",
    "    # Compute the mean of the signal\n",
    "    mean = np.mean(signal)\n",
    "\n",
    "    # Perform autocorrelation only if the signal is not empty\n",
    "    correlation = np.correlate(signal - mean, signal - mean, mode='full')\n",
    "\n",
    "    return correlation[len(signal) - 1:]\n",
    "\n",
    "\n",
    "\n",
    "def get_pitch(signal, sample_rate=44100):\n",
    "    if check_silence(signal):\n",
    "        return 0\n",
    "\n",
    "    correlation_result = autocorrelate(signal)\n",
    "    peaks, _ = find_peaks(correlation_result, height=0.1)\n",
    "\n",
    "    if len(peaks) == 0:\n",
    "        return 0\n",
    "\n",
    "    period = peaks[0]\n",
    "    return sample_rate / period\n",
    "\n",
    "\n",
    "def check_silence(signal, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Check if the provided audio signal is silent.\n",
    "    \n",
    "    Args:\n",
    "    signal (numpy array): The audio signal.\n",
    "    threshold (float): Amplitude threshold for silence detection.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the signal is silent, False otherwise.\n",
    "    \"\"\"\n",
    "    if signal.size == 0:\n",
    "        return True  \n",
    "    if np.max(np.abs(signal)) < threshold:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc813b5-41d2-4d2c-88b4-8f973526bced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90acabe9-9827-42e5-8427-dda43387c2c0",
   "metadata": {},
   "source": [
    "# Long Utterance Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4ecc03c-7387-4d13-9cb3-2a538b60859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_SPEAK, W_PAUSE = 1.5*c, 0.8*c #1.5, 0.8  \n",
    "\n",
    "def long_utterance_model(speech_duration, \n",
    "                         silence_duration, \n",
    "                         last_bc_time, \n",
    "                         current_time):\n",
    "    \n",
    "    if speech_duration >= W_SPEAK and silence_duration >= W_PAUSE:\n",
    "        \n",
    "        if current_time - last_bc_time > BC_RATE:\n",
    "        \n",
    "            return True \n",
    "        \n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b3f01d-7277-4320-af38-04386e7fa6bc",
   "metadata": {},
   "source": [
    "# Long Pause Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f34c36f-7c5b-4aec-b31b-083e0457b700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long Pause Model\n",
    "LP_SPEAK, LP_PAUSE = 1.0, 1.7\n",
    "\n",
    "def long_pause_model(speech_duration, \n",
    "                     silence_duration, \n",
    "                     last_bc_time, \n",
    "                     current_time):\n",
    "    \n",
    "    if speech_duration >= LP_SPEAK and silence_duration >= LP_PAUSE:\n",
    "        \n",
    "        if current_time - last_bc_time > BC_RATE:\n",
    "            \n",
    "            return True \n",
    "        \n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79520c89-f373-4275-ad3c-5b2284308106",
   "metadata": {},
   "source": [
    "# Pitch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9b2c1c4-5273-4ba8-a24d-4615ab6e063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_AND_P_PAUSE = 0.4  \n",
    "P_AND_P_SPEAK = 1.0  \n",
    "P_AND_P_LENGTH = 0.3 \n",
    "P_AND_P_SLOPE = 0.25  # 25% rise or drop\n",
    "\n",
    "def analyze_pitch_change(audio_data, duration, slope_threshold):\n",
    "    # Assuming get_pitch function calculates the pitch of the audio segment\n",
    "    # Calculate pitch at the start and end of the duration\n",
    "    start_pitch = get_pitch(audio_data[:int(duration/2)])\n",
    "    end_pitch = get_pitch(audio_data[-int(duration/2):])\n",
    "\n",
    "    # Calculate the percentage change in pitch\n",
    "    if start_pitch == 0:  # Avoid division by zero\n",
    "        return False\n",
    "    pitch_change = (end_pitch - start_pitch) / start_pitch\n",
    "\n",
    "    # Check if the change meets or exceeds the threshold\n",
    "    return abs(pitch_change) >= slope_threshold\n",
    "\n",
    "\n",
    "\n",
    "def pitch_model(speech_data, silence_duration, \n",
    "                last_bc_time, current_time):\n",
    "    pitch = analyze_pitch_change(speech_data, P_AND_P_LENGTH, P_AND_P_SLOPE)\n",
    "    if (silence_duration >= P_AND_P_PAUSE) and pitch:\n",
    "        \n",
    "        if current_time - last_bc_time > BC_RATE:\n",
    "            return True   \n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eda74e3-e77d-4739-980c-f72093d8be8b",
   "metadata": {},
   "source": [
    "# Energy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c959d93-65e6-45f0-9add-ee60596dec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Energy Model\n",
    "E_PAUSE, E_SLOPE_LENGTH, E_SLOPE = 0.3, 0.5, 0.3\n",
    "\n",
    "def analyze_energy_change(audio_data, duration, slope_threshold):\n",
    "    \n",
    "    # Calculate RMS energy at the start and end of the duration\n",
    "    start_energy = np.sqrt(np.mean(np.square(audio_data[:int(duration/2)])))\n",
    "    \n",
    "    end_energy = np.sqrt(np.mean(np.square(audio_data[-int(duration/2):])))\n",
    "\n",
    "    # Calculate the percentage change in energy\n",
    "    if start_energy == 0:  # Avoid division by zero\n",
    "        return False\n",
    "    energy_change = (end_energy - start_energy) / start_energy\n",
    "\n",
    "    # Check if the change meets or exceeds the threshold\n",
    "    return abs(energy_change) >= slope_threshold\n",
    "\n",
    "E_PAUSE = 0.3  # 300 ms\n",
    "E_SLOPE_LENGTH = 0.5  # Energy analysis duration 500 ms\n",
    "E_SLOPE = 0.3  # 30% rise or drop\n",
    "\n",
    "def energy_model(speech_data, silence_duration, last_bc_time, current_time):\n",
    "    \n",
    "    energy_status = analyze_energy_change(speech_data, E_SLOPE_LENGTH, E_SLOPE)\n",
    "    \n",
    "    if (silence_duration >= E_PAUSE) and energy_status:\n",
    "        \n",
    "        if current_time - last_bc_time > BC_RATE:\n",
    "            \n",
    "            return True \n",
    "        \n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25b80d6-3ffb-4d90-88d4-80e191f7416f",
   "metadata": {},
   "source": [
    "# Callback function for processing audio stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f763066-34cc-425d-91ce-b1248503c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_callback(indata, frames, time, status):\n",
    "    \n",
    "    global speech_duration, silence_duration, last_bc_time\n",
    "    \n",
    "    audio_data = np.frombuffer(indata.copy(), dtype=np.float32)\n",
    "\n",
    "\n",
    "    is_silent = check_silence(audio_data)  # Use the check_silence function\n",
    "\n",
    "    # Update durations\n",
    "    if is_silent:\n",
    "        silence_duration += DURATION\n",
    "        print(\"S\", end=\"\")\n",
    "    else:\n",
    "        speech_duration += DURATION\n",
    "        print(\"I\", end=\"\")\n",
    "\n",
    "    # Check models and play beep if conditions are met\n",
    "    current_time = tm.perf_counter() # float value of time in seconds\n",
    "    \n",
    "    utterance = long_utterance_model(speech_duration, silence_duration, \n",
    "                                     last_bc_time, current_time)\n",
    "    \n",
    "    \"\"\"\n",
    "    pause = long_pause_model(speech_duration, silence_duration, \n",
    "                            last_bc_time, current_time)\n",
    "    \n",
    "    pitch = pitch_model(audio_data, silence_duration, \n",
    "                        last_bc_time, current_time)\n",
    "    \n",
    "    energy = energy_model(audio_data, silence_duration, \n",
    "                          last_bc_time, current_time)\n",
    "    \"\"\"\n",
    "    if utterance: #and pause and pitch and energy:\n",
    "        play_soft_beep()\n",
    "        silence_duration = 0\n",
    "        speech_duration = 0\n",
    "        last_bc_time = current_time  # Update the time of the last beep\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fc64ad-5e29-48ea-a3cd-a6d023b16957",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c0c3fc7-c5a8-41dd-9322-adf87425f485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording and analyzing speech. Press Ctrl+C to stop.\n",
      "SSSSSSSSSSSSSSSIISSSSSIIIISSSSSSSIII BC \n",
      "\n",
      "SISSISSSSSSSSSSSSSSSSSSSSSSSIIIIIII BC \n",
      "\n",
      "SSSSSS"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 20\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m             tm\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.1\u001b[39m)  \u001b[38;5;66;03m# Keep the main thread alive\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [11], line 16\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecording and analyzing speech. Press Ctrl+C to stop.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m     \u001b[43mtm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    global speech_duration, silence_duration, last_bc_time\n",
    "    speech_duration = 0.0\n",
    "    silence_duration = 0.0\n",
    "    last_bc_time = 0.0\n",
    "\n",
    "    # Open a stream for real-time audio processing\n",
    "    with sd.InputStream(callback=audio_callback, \n",
    "                        channels=CHANNELS, \n",
    "                        samplerate=SAMPLERATE, \n",
    "                        blocksize=int(SAMPLERATE * DURATION)):\n",
    "        \n",
    "        print(\"Recording and analyzing speech. Press Ctrl+C to stop.\")\n",
    "        while True:\n",
    "            \n",
    "            tm.sleep(0.1)  # Keep the main thread alive\n",
    "            \n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5861175-aff0-477a-8a43-8699dacf1e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
